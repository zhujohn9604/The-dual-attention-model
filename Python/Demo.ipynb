{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A demo for training the dual-attn model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hojin_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>urls</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>hightechflag</th>\n",
       "      <th>company_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7010401009665</td>\n",
       "      <td>株式会社広済堂ホールディングス</td>\n",
       "      <td>http://www.kosaido.co.jp/service/communication...</td>\n",
       "      <td>施工|られ|硬質|管理|集計|写真|人材|安全|Copyright|こうした|SERVICE...</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7010401009665</td>\n",
       "      <td>株式会社広済堂ホールディングス</td>\n",
       "      <td>http://www.kosaido.co.jp/service/human/</td>\n",
       "      <td>国籍|誇り|就職|誇る|管理|就労|人材|安全|Workin|Copyright|人数|SE...</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7010401009665</td>\n",
       "      <td>株式会社広済堂ホールディングス</td>\n",
       "      <td>http://www.kosaido.co.jp/csr/business/</td>\n",
       "      <td>着実|一貫|管理|人材|安全|Copyright|確立|及ぼす|SERVICE|オリジナル|...</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7010401009665</td>\n",
       "      <td>株式会社広済堂ホールディングス</td>\n",
       "      <td>http://www.kosaido.co.jp/service/human/#overseas</td>\n",
       "      <td>国籍|誇り|就職|誇る|管理|就労|人材|安全|Workin|Copyright|人数|SE...</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7010401009665</td>\n",
       "      <td>株式会社広済堂ホールディングス</td>\n",
       "      <td>http://www.kosaido.co.jp/service/communication...</td>\n",
       "      <td>施工|られ|硬質|管理|集計|写真|人材|安全|Copyright|こうした|SERVICE...</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119663</th>\n",
       "      <td>6010401027577</td>\n",
       "      <td>本田技研工業株式会社</td>\n",
       "      <td>http://www.honda.co.jp/guide/?from=navi_drawer</td>\n",
       "      <td>向かう|エンジン|よく|ニュースルームトップ|会社|採用|リリース|モビリティサービス|そし...</td>\n",
       "      <td>1</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119664</th>\n",
       "      <td>6010401027577</td>\n",
       "      <td>本田技研工業株式会社</td>\n",
       "      <td>http://www.honda.co.jp/topics/?from=navi_drawer</td>\n",
       "      <td>エンジン|よく|ニュースルームトップ|会社|採用|リリース|モビリティサービス|モータースポ...</td>\n",
       "      <td>1</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119665</th>\n",
       "      <td>6010401027577</td>\n",
       "      <td>本田技研工業株式会社</td>\n",
       "      <td>http://www.honda.co.jp/recall/?from=navi_header</td>\n",
       "      <td>エンジン|よく|ニュースルームトップ|取扱|心配|会社|採用|リリース|モビリティサービス|...</td>\n",
       "      <td>1</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119666</th>\n",
       "      <td>6010401027577</td>\n",
       "      <td>本田技研工業株式会社</td>\n",
       "      <td>http://www.honda.co.jp/event/?from=navi_drawer</td>\n",
       "      <td>られ|レース|モビリティサービス|人材|安全|モビリティーリゾート|参加|シリーズ|大人|変...</td>\n",
       "      <td>1</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119667</th>\n",
       "      <td>6010401027577</td>\n",
       "      <td>本田技研工業株式会社</td>\n",
       "      <td>http://www.honda.co.jp/stories/?from=top_stori...</td>\n",
       "      <td>技術|エンジン|よく|ニュースルームトップ|挑み|レース|叶える|会社|クリーン|リリース|...</td>\n",
       "      <td>1</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119655 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             hojin_id     company_name  \\\n",
       "0       7010401009665  株式会社広済堂ホールディングス   \n",
       "1       7010401009665  株式会社広済堂ホールディングス   \n",
       "2       7010401009665  株式会社広済堂ホールディングス   \n",
       "3       7010401009665  株式会社広済堂ホールディングス   \n",
       "4       7010401009665  株式会社広済堂ホールディングス   \n",
       "...               ...              ...   \n",
       "119663  6010401027577       本田技研工業株式会社   \n",
       "119664  6010401027577       本田技研工業株式会社   \n",
       "119665  6010401027577       本田技研工業株式会社   \n",
       "119666  6010401027577       本田技研工業株式会社   \n",
       "119667  6010401027577       本田技研工業株式会社   \n",
       "\n",
       "                                                     urls  \\\n",
       "0       http://www.kosaido.co.jp/service/communication...   \n",
       "1                 http://www.kosaido.co.jp/service/human/   \n",
       "2                  http://www.kosaido.co.jp/csr/business/   \n",
       "3        http://www.kosaido.co.jp/service/human/#overseas   \n",
       "4       http://www.kosaido.co.jp/service/communication...   \n",
       "...                                                   ...   \n",
       "119663     http://www.honda.co.jp/guide/?from=navi_drawer   \n",
       "119664    http://www.honda.co.jp/topics/?from=navi_drawer   \n",
       "119665    http://www.honda.co.jp/recall/?from=navi_header   \n",
       "119666     http://www.honda.co.jp/event/?from=navi_drawer   \n",
       "119667  http://www.honda.co.jp/stories/?from=top_stori...   \n",
       "\n",
       "                                          cleaned_content  hightechflag  \\\n",
       "0       施工|られ|硬質|管理|集計|写真|人材|安全|Copyright|こうした|SERVICE...             0   \n",
       "1       国籍|誇り|就職|誇る|管理|就労|人材|安全|Workin|Copyright|人数|SE...             0   \n",
       "2       着実|一貫|管理|人材|安全|Copyright|確立|及ぼす|SERVICE|オリジナル|...             0   \n",
       "3       国籍|誇り|就職|誇る|管理|就労|人材|安全|Workin|Copyright|人数|SE...             0   \n",
       "4       施工|られ|硬質|管理|集計|写真|人材|安全|Copyright|こうした|SERVICE...             0   \n",
       "...                                                   ...           ...   \n",
       "119663  向かう|エンジン|よく|ニュースルームトップ|会社|採用|リリース|モビリティサービス|そし...             1   \n",
       "119664  エンジン|よく|ニュースルームトップ|会社|採用|リリース|モビリティサービス|モータースポ...             1   \n",
       "119665  エンジン|よく|ニュースルームトップ|取扱|心配|会社|採用|リリース|モビリティサービス|...             1   \n",
       "119666  られ|レース|モビリティサービス|人材|安全|モビリティーリゾート|参加|シリーズ|大人|変...             1   \n",
       "119667  技術|エンジン|よく|ニュースルームトップ|挑み|レース|叶える|会社|クリーン|リリース|...             1   \n",
       "\n",
       "       company_label  \n",
       "0             others  \n",
       "1             others  \n",
       "2             others  \n",
       "3             others  \n",
       "4             others  \n",
       "...              ...  \n",
       "119663    automobile  \n",
       "119664    automobile  \n",
       "119665    automobile  \n",
       "119666    automobile  \n",
       "119667    automobile  \n",
       "\n",
       "[119655 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from tokenizer import Tokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score\n",
    "from dual_attn import DualAttnModel\n",
    "\n",
    "data = pd.read_csv('listed_web_train.csv')\n",
    "data = data.dropna().drop_duplicates()\n",
    "cleaned_content = ['|'.join(list(set(i.split(\"|\")))) for i in data.cleaned_content]\n",
    "data['cleaned_content'] = cleaned_content\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hojin_ids = list(set(data.hojin_id))\n",
    "\n",
    "sample_data = pd.DataFrame({})\n",
    "max_page = 32\n",
    "\n",
    "for hojin_id in hojin_ids:\n",
    "    temp = data[data.hojin_id == hojin_id]\n",
    "    if temp.shape[0] <= max_page:\n",
    "        sample_data = pd.concat([sample_data, temp], ignore_index=True)\n",
    "    else:\n",
    "        sample_data = pd.concat([sample_data, temp.iloc[:max_page, :]], ignore_index=True)\n",
    "\n",
    "num_words = [len(i.split('|')) for i in sample_data.cleaned_content]\n",
    "sample_data['num_words'] = num_words\n",
    "sample_data = sample_data[sample_data.num_words > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in pretrained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wv_dict_listed.pkl', 'rb') as fp:\n",
    "    wv_dict = pickle.load(fp)\n",
    "\n",
    "vectors = np.array(list(wv_dict.values()))\n",
    "words = list(wv_dict.keys())\n",
    "vectors_all = np.vstack([np.zeros(300), vectors])\n",
    "vectors_all = torch.tensor(vectors_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3829/3829 [00:12<00:00, 316.31it/s]\n"
     ]
    }
   ],
   "source": [
    "hojin_ids = list(set(sample_data.hojin_id))\n",
    "hojin_ids = [int(i) for i in hojin_ids]\n",
    "\n",
    "tokenizer = Tokenizer(words, max_len=864, data = sample_data)\n",
    "\n",
    "web_vectors = [tokenizer.encode_webportfolio(company_id=idx, max_page=max_page) for idx in tqdm(hojin_ids)]\n",
    "\n",
    "seq_ids = torch.tensor([i[1] for i in web_vectors])\n",
    "num_pages = torch.tensor([i[0] for i in web_vectors])\n",
    "seq_lengths = tokenizer.max_len - torch.sum(seq_ids == 0, axis=-1)\n",
    "\n",
    "labels = torch.tensor([tokenizer.get_label(i) for i in hojin_ids])\n",
    "hojin_ids = torch.tensor(hojin_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "dataset = TensorDataset(seq_ids, num_pages, seq_lengths, labels, hojin_ids)\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader, model):\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    i = 0\n",
    "    gold_labels = []\n",
    "    pred_labels = []\n",
    "    for ind, batch in tqdm(enumerate(data_loader), ncols=80):\n",
    "                \n",
    "        seq_ids, num_pages, seq_lengths, label_list, hojin = batch        \n",
    "        outputs, _, _, _, _, _, _ = model(seq_ids.to(device), num_pages.to(device), seq_lengths.to(device))\n",
    "        preds = (outputs>0.5).squeeze()\n",
    "\n",
    "        gold_labels += list(label_list.cpu().numpy())\n",
    "        pred_labels += list(preds.cpu().numpy())\n",
    "        num = (preds.cpu() == label_list.bool()).sum().cpu().item()\n",
    "        count += num\n",
    "        i += 1\n",
    "    accuracy = count*1.0/(i * batch_size)\n",
    "    print('Evaluation accuracy:', accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings loaded\n"
     ]
    }
   ],
   "source": [
    "vectors = np.array(list(wv_dict.values()))\n",
    "words = list(wv_dict.keys())\n",
    "vectors_all = np.vstack([np.zeros(300), vectors])\n",
    "\n",
    "torch.manual_seed(1218)\n",
    "loss_function = nn.BCELoss()\n",
    "scale = 10\n",
    "\n",
    "model = DualAttnModel(vocab_size=len(words)+1, embed_dim=300, hidden_dim=300, \n",
    "                             label_dim=1, scale=10, page_scale=10)\n",
    "model.load_vector(pretrained_vectors=vectors_all, trainable=True)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.02, weight_decay=0.0000, lr_decay=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:25, 19.05it/s]\n",
      "5it [00:00, 42.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:   0.51237556945409\n",
      "Training Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:10, 44.91it/s]\n",
      "2it [00:00, 18.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.8215031315240083\n",
      "Epoch: 1\n",
      "####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:24, 19.32it/s]\n",
      "5it [00:00, 42.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:   0.41831847727999233\n",
      "Training Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:10, 45.28it/s]\n",
      "2it [00:00, 18.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.8413361169102297\n",
      "Epoch: 2\n",
      "####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:24, 19.22it/s]\n",
      "5it [00:00, 42.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:   0.3786822805386917\n",
      "Training Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:10, 45.29it/s]\n",
      "4it [00:00, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.8593423799582464\n",
      "Epoch: 3\n",
      "####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:24, 19.35it/s]\n",
      "5it [00:00, 44.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:   0.3550381890983829\n",
      "Training Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:10, 44.77it/s]\n",
      "4it [00:00, 18.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.8679540709812108\n",
      "Epoch: 4\n",
      "####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:24, 19.35it/s]\n",
      "5it [00:00, 44.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:   0.3328929867281183\n",
      "Training Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:10, 45.18it/s]\n",
      "2it [00:00, 18.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.877348643006263\n",
      "Epoch: 5\n",
      "####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:24, 19.34it/s]\n",
      "5it [00:00, 43.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:   0.31649616631523814\n",
      "Training Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:10, 45.12it/s]\n",
      "2it [00:00, 18.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.8825678496868476\n",
      "Epoch: 6\n",
      "####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:24, 19.36it/s]\n",
      "5it [00:00, 42.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:   0.3023038289975983\n",
      "Training Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:10, 45.17it/s]\n",
      "2it [00:00, 18.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.8875260960334029\n",
      "Epoch: 7\n",
      "####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:24, 19.35it/s]\n",
      "5it [00:00, 44.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:   0.29181726925419466\n",
      "Training Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:10, 45.35it/s]\n",
      "2it [00:00, 18.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.8903966597077244\n",
      "Epoch: 8\n",
      "####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:24, 19.40it/s]\n",
      "5it [00:00, 43.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:   0.28064770434225905\n",
      "Training Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:10, 45.37it/s]\n",
      "2it [00:00, 18.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.8950939457202505\n",
      "Epoch: 9\n",
      "####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:24, 19.37it/s]\n",
      "4it [00:00, 39.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:   0.2722041474255889\n",
      "Training Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:11, 43.42it/s]\n",
      "4it [00:00, 19.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.8974425887265136\n",
      "Epoch: 10\n",
      "####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:24, 19.35it/s]\n",
      "5it [00:00, 43.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:   0.26562123869629184\n",
      "Training Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:10, 45.39it/s]\n",
      "2it [00:00, 18.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.9010960334029228\n",
      "Epoch: 11\n",
      "####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:24, 19.32it/s]\n",
      "5it [00:00, 42.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:   0.25670159771186185\n",
      "Training Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [00:10, 45.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.9034446764091858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_acc = 0\n",
    "for i in range(12):\n",
    "    print('Epoch:', i)\n",
    "    print('#'*20)\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    model.train()\n",
    "    for ind, batch in tqdm(enumerate(train_dataloader), ncols=80):\n",
    "        seq_ids, num_pages, seq_lengths, label_list, hojin = batch\n",
    "        model.zero_grad()\n",
    "        preds, _, _, _, _, _, _ = model(seq_ids.to(device), num_pages.to(device), seq_lengths.to(device))\n",
    "        loss = loss_function(preds.squeeze(), label_list.to(device).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.cpu().item()*len(seq_ids)\n",
    "        count += len(seq_ids)\n",
    "    print('total_loss:  ', total_loss/count)\n",
    "    print('Training Accuracy')\n",
    "    evaluate(train_dataloader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3829/3829 [00:12<00:00, 317.94it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('wv_dict_listed.pkl', 'rb') as fp:\n",
    "    wv_dict = pickle.load(fp)\n",
    "\n",
    "import torch\n",
    "vectors = np.array(list(wv_dict.values()))\n",
    "words = list(wv_dict.keys())\n",
    "vectors_all = np.vstack([np.zeros(300), vectors])\n",
    "vectors_all = torch.tensor(vectors_all)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "hojin_ids = list(set(sample_data.hojin_id))\n",
    "hojin_ids = [int(i) for i in hojin_ids]\n",
    "\n",
    "tokenizer = Tokenizer(words, max_len=864, data = sample_data)\n",
    "\n",
    "web_vectors = [tokenizer.encode_webportfolio(company_id=idx, max_page=max_page) for idx in tqdm(hojin_ids)]\n",
    "\n",
    "seq_ids = torch.tensor([i[1] for i in web_vectors])\n",
    "num_pages = torch.tensor([i[0] for i in web_vectors])\n",
    "seq_lengths = tokenizer.max_len - torch.sum(seq_ids == 0, axis=-1)\n",
    "labels = torch.tensor([tokenizer.get_label(i) for i in hojin_ids])\n",
    "hojin_ids = torch.tensor(hojin_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  url    weight  page_score\n",
      "0                     http://www.hakuto.co.jp/irinfo/  0.000000    0.065175\n",
      "1            http://www.hakuto.co.jp/irinfo/announce/  0.000000    0.082474\n",
      "2                            http://www.g5-hakuto.jp/  0.072509    0.160616\n",
      "3              http://www.hakuto.co.jp/profile/ethic/  0.000000    0.005596\n",
      "4     http://www.hakuto.co.jp/news/2022/20221024.html  0.000000   -0.131699\n",
      "5     http://www.hakuto.co.jp/news/2022/20221111.html  0.034292    0.122399\n",
      "6         http://www.hakuto.co.jp/products/equipment/  0.244028    0.332135\n",
      "7   http://www.hakuto.co.jp/profile/outline/strate...  0.000000    0.013428\n",
      "8                    http://www.hakuto.co.jp/profile/  0.010578    0.098686\n",
      "9        http://www.hakuto.co.jp/products/components/  0.000000    0.075061\n",
      "10  http://www.hakuto.co.jp/profile/outline/embedd...  0.000000   -0.090604\n",
      "11    http://www.hakuto.co.jp/news/2022/20221102.html  0.000000    0.021570\n",
      "12    http://www.hakuto.co.jp/news/2022/20221013.html  0.000000    0.033083\n",
      "13                       http://www.hakuto.co.jp/eco/  0.036433    0.124541\n",
      "14                  http://www.hakuto.co.jp/products/  0.136935    0.225043\n",
      "15                  http://www.hakuto.co.jp/site_map/  0.000000   -0.015925\n",
      "16    http://www.hakuto.co.jp/news/2022/20221020.html  0.000000   -0.015802\n",
      "17                   http://www.hakuto.co.jp/contact/  0.000000   -0.033910\n",
      "18  http://www.hakuto.co.jp/profile/outline/advanc...  0.048944    0.137051\n",
      "19                  https://www.process.hakuto.co.jp/  0.289600    0.377707\n",
      "20                           http://www.hakuto.co.jp/  0.000000   -0.065757\n",
      "21                   http://www.hakuto.co.jp/privacy/  0.000000   -0.176803\n",
      "22        http://www.hakuto.co.jp/products/chemicals/  0.020991    0.109098\n",
      "23          http://www.hakuto.co.jp/products/devices/  0.000000    0.025212\n",
      "24                http://www.hakuto.co.jp/sitepolicy/  0.000000   -0.239630\n",
      "25                      http://www.hakuto.co.jp/news/  0.000000    0.058749\n",
      "26                       http://www.hakuto-vacuum.jp/  0.105690    0.193798\n",
      "27                      http://www.hakuto.co.jp/news/  0.000000    0.048790\n",
      "28                           http://www.hakuto.co.jp/  0.000000   -0.085692\n",
      "29    http://www.hakuto.co.jp/news/2022/20221115.html  0.000000   -0.268807\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "t = 568\n",
    "probs, senti_scores, attn, page_attn, final_vec, page_score, _ = model(seq_ids[t:(t+1)].to(device), num_pages[t:(t+1)].to(device), seq_lengths[t:(t+1)].to(device))\n",
    "id_to_token = tokenizer.id_to_token\n",
    "id_to_token[0] = '#'\n",
    "\n",
    "\n",
    "sents = []\n",
    "for i in range(num_pages[t:(t+1)].tolist()[0]):\n",
    "    sents.append(' '.join([id_to_token[w] for w in seq_ids[t:(t+1)][0][i].tolist()]))\n",
    "    \n",
    "df = pd.DataFrame({'url': list(sample_data[sample_data.hojin_id == int(hojin_ids[t].tolist())].urls), \n",
    "                   'weight': page_attn.view(-1)[:num_pages[t:(t+1)].tolist()[0]].tolist(),\n",
    "                   'page_score': page_score.view(-1)[page_score.view(-1) > -9999].tolist()\n",
    "                   })\n",
    "print(df)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def colorize(words, color_array):\n",
    "    cmap=matplotlib.cm.Blues\n",
    "    template = '<span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n",
    "    colored_string = ''\n",
    "    for word, color in zip(words, color_array):\n",
    "        color = matplotlib.colors.rgb2hex(cmap(color)[:3])\n",
    "        #print(color)\n",
    "        colored_string += template.format(color, '&nbsp' + word + '&nbsp')\n",
    "    return colored_string\n",
    "\n",
    "\n",
    "word_col = []\n",
    "color_arrays = []\n",
    "for i in list(df.index):\n",
    "    \n",
    "    sent = sents[i]\n",
    "    attn1 = attn.squeeze()[i]\n",
    "    \n",
    "    words = sent.split()\n",
    "    color_array = attn1.view(-1).tolist()\n",
    "    \n",
    "    word_col = word_col + [str(page_attn.view(-1).tolist()[i])]\n",
    "    color_array = color_array + [1]\n",
    "    \n",
    "    word_col.extend(words)\n",
    "    color_arrays.extend(color_array)\n",
    "    \n",
    "color_arrays = np.array(color_arrays)\n",
    "s = colorize(word_col, color_arrays * 100)\n",
    "\n",
    "with open('colorize_all.html', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def colorize(words, color_array):\n",
    "    cmap=matplotlib.cm.Blues\n",
    "    template = '<span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n",
    "    colored_string = ''\n",
    "    for word, color in zip(words, color_array):\n",
    "        color = matplotlib.colors.rgb2hex(cmap(color)[:3])\n",
    "        print(color)\n",
    "        colored_string += template.format(color, '&nbsp' + word + '&nbsp')\n",
    "    return colored_string\n",
    "\n",
    "def select_keywords(attn_w, words, n=10):\n",
    "    combo = [(i, j) for i, j in zip(attn_w, words) if i != 0]\n",
    "    attn_w = np.array([i[0] for i in combo])\n",
    "    words = [i[1] for i in combo]\n",
    "    attn_diff = attn_w.max() - attn_w\n",
    "    attn_thres = np.percentile(attn_diff, n)\n",
    "    selected_keywords = [i for i, j in zip(words, attn_diff) if j <= attn_thres]\n",
    "    selected_keywords_show = [0.6 if j <= attn_thres else 0 for i, j in zip(words, attn_diff)]\n",
    "    return selected_keywords, selected_keywords_show\n",
    "\n",
    "url_col = []\n",
    "text_col = []\n",
    "sents_selected = []\n",
    "weight_col = []\n",
    "hojin_id_col = []\n",
    "hightechflag_col = []\n",
    "model.eval()\n",
    "\n",
    "final_vecs = []\n",
    "web_vecs = []\n",
    "page_attns = []\n",
    "urls = []\n",
    "\n",
    "\n",
    "for t in range(len(hojin_ids)):\n",
    "    \n",
    "    probs, senti_scores, attn, page_attn, final_vec, page_score, web_vec = model(seq_ids[t:(t+1)].to(device), num_pages[t:(t+1)].to(device), seq_lengths[t:(t+1)].to(device))\n",
    "    id_to_token = tokenizer.id_to_token\n",
    "    id_to_token[0] = '#'\n",
    "\n",
    "\n",
    "    sents = []\n",
    "    for i in range(num_pages[t:(t+1)].tolist()[0]):\n",
    "        sents.append(' '.join([id_to_token[w] for w in seq_ids[t:(t+1)][0][i].tolist()]))\n",
    "\n",
    "    final_vecs.append(final_vec.detach().cpu().numpy())\n",
    "    df = pd.DataFrame({'url': list(sample_data[sample_data.hojin_id == int(hojin_ids[t].tolist())].urls), \n",
    "                   'hojin_id': list(sample_data[sample_data.hojin_id == int(hojin_ids[t].tolist())].hojin_id),\n",
    "                   'hightechflag': list(sample_data[sample_data.hojin_id == int(hojin_ids[t].tolist())].hightechflag),\n",
    "                   'text':list(sample_data[sample_data.hojin_id == int(hojin_ids[t].tolist())].cleaned_content),             \n",
    "                   'weight': page_attn.view(-1)[:num_pages[t:(t+1)].tolist()[0]].tolist(),\n",
    "                   'page_score': page_score.view(-1)[page_score.view(-1) > -9999].tolist(),\n",
    "                   #'web_vecs': list(web_vec[0])[:num_pages[t:(t+1)].tolist()[0]]\n",
    "                   })\n",
    "    df = df[df.weight > 0].reset_index()\n",
    "\n",
    "\n",
    "    hojin_id_col.extend(df.hojin_id)\n",
    "    hightechflag_col.extend(df.hightechflag)\n",
    "    url_col.extend(df.url)\n",
    "    text_col.extend(df.text)\n",
    "    weight_col.extend(df.weight)\n",
    "    \n",
    "    for i in list(df['index']):\n",
    "        sent = sents[i]\n",
    "        attn1 = attn.squeeze()[i]\n",
    "    \n",
    "        words = sent.split()\n",
    "        color_array = np.array(attn1.view(-1).tolist())\n",
    "    \n",
    "        selected_keywords, selected_keywords_show = select_keywords(color_array, words, n=20)\n",
    "\n",
    "        sents_selected.append([j for j, k in zip(words, selected_keywords_show) if k != 0])\n",
    "    \n",
    "\n",
    "sents_selected = ['|'.join(i) for i in sents_selected]\n",
    "selected_df = pd.DataFrame({\n",
    "    'hojin_id': hojin_id_col, \n",
    "    'url': url_col,\n",
    "    'weight': weight_col,\n",
    "    'text':text_col,\n",
    "    'sents': sents_selected, 'hightechflag': hightechflag_col,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
